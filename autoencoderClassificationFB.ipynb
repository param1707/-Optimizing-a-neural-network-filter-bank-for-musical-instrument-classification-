{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoderClassificationFB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTPVtlJ3o9_O"
      },
      "source": [
        "# Convolutional Neural Network Filter Bank for Musical Instruments Classification\n",
        "## Author: Renato de Castro Rabelo Profeta\n",
        "### Date: October, 2020\n",
        "#### Applied Media Systems Group, Ilmenau University of Technology, Germany"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSD201tXqbuM"
      },
      "source": [
        "## Colab Runtime Configurations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-nyL1r2qaeu"
      },
      "source": [
        "# Install torchaudio\n",
        "!pip install torchaudio -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-22xIXFj8PK"
      },
      "source": [
        "## Imports and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqfbUD8bqkc9"
      },
      "source": [
        "# Imports\n",
        "\n",
        "## Numerical Computing\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "## File System and Files Handling\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "## Python Serialization\n",
        "import pickle\n",
        "\n",
        "## Audio Processing\n",
        "import librosa.display, librosa\n",
        "import torchaudio\n",
        "\n",
        "## Plotting and Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "from IPython.core.display import HTML, display, Image\n",
        "\n",
        "## Machine Learning Â´\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "## Deep Learning\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fmW5300PjCT"
      },
      "source": [
        "# Seeds for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTI880yTj7X1"
      },
      "source": [
        "# Configurations\n",
        "## Create Directory for Checkpoints\n",
        "!mkdir -p checkpoints\n",
        "\n",
        "## Check CPU or GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3-6RmeRQAo"
      },
      "source": [
        "# Configure Tensorboard\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXi5FDT1P0Oh"
      },
      "source": [
        "logs_base_dir = \"runs\"\n",
        "os.makedirs(logs_base_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A86hNqrZJlsk"
      },
      "source": [
        "## Download the dataset from Dropbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT77r8-iIaDz"
      },
      "source": [
        "# Download the dataset from Dropbox\n",
        "!wget -O dataset.zip https://www.dropbox.com/s/su4rvaipccm1lit/all-samples_npy_pkl.zip?dl=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzW5oU4XLA0y"
      },
      "source": [
        "## Extract .zip "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymCG8tSNIhWA"
      },
      "source": [
        "with ZipFile('dataset.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzVlI8yiTAUR"
      },
      "source": [
        "## Get Dataset Metadata from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BWzPmdwJCEA"
      },
      "source": [
        "# Clone github in Google Colab\n",
        "!git clone https://github.com/param1707/-Optimizing-a-neural-network-filter-bank-for-musical-instrument-classification-.git "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MjxFiKakuBR"
      },
      "source": [
        "# Load Train Set\n",
        "with open('./-Optimizing-a-neural-network-filter-bank-for-musical-instrument-classification-/datasetMetadata/train_set_dataframe.pkl', 'rb') as f:\n",
        "  train_set = pickle.load(f)\n",
        "#Load Test Set\n",
        "with open('./-Optimizing-a-neural-network-filter-bank-for-musical-instrument-classification-/datasetMetadata/test_set_dataframe.pkl', 'rb') as f:\n",
        "  test_set = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJUzL2P6lNwc"
      },
      "source": [
        "## Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMVWVOzBuQCI"
      },
      "source": [
        "# Encode Labels Train Set\n",
        "labelencoder = LabelEncoder()\n",
        "labelencoder.fit(train_set['class'].values.tolist())\n",
        "print(len(labelencoder.classes_), \"classes:\", \", \".join(list(labelencoder.classes_)))\n",
        "classes_int_train = labelencoder.transform(train_set['class'].values.tolist())\n",
        "\n",
        "#OneHotEncoding\n",
        "encoder=OneHotEncoder(sparse=False, categories=\"auto\")\n",
        "onehot_labels_train=encoder.fit_transform(classes_int_train.reshape(len(classes_int_train),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbSLYoDio5Cs"
      },
      "source": [
        "# Encode Labels Test Set\n",
        "labelencoder.fit(test_set['class'].values.tolist())\n",
        "print(len(labelencoder.classes_), \"classes:\", \", \".join(list(labelencoder.classes_)))\n",
        "classes_int_test = labelencoder.transform(test_set['class'].values.tolist())\n",
        "\n",
        "#OneHotEncoding\n",
        "encoder=OneHotEncoder(sparse=False, categories=\"auto\")\n",
        "onehot_labels_test=encoder.fit_transform(classes_int_test.reshape(len(classes_int_test),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJmUBDluemWz"
      },
      "source": [
        "## Create PyTorch Datasets for Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOfWtg5kNl93"
      },
      "source": [
        "# Dataset Class\n",
        "class dataset(Dataset):\n",
        "    \"\"\"An abstract class representing a Dataset.\n",
        "\n",
        "    Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau Germany\n",
        "    \"\"\"\n",
        "    def __init__(self, files, labels):\n",
        "        self.labels = labels\n",
        "        self.files = files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      x_numpy = np.load(self.files[index])\n",
        "      X = torch.from_numpy(x_numpy)\n",
        "      X /= torch.abs(X).max()  # Normalize\n",
        "      X = torch.reshape(X,(1,-1)) # Reshape for Model\n",
        "      y_labels = torch.tensor(self.labels[index]) #Labels Out\n",
        "      return X,y_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNeq5XyDjI0J"
      },
      "source": [
        "# Create Sets\n",
        "train_set_torch = dataset(train_set['filename'].values.tolist(), onehot_labels_train)\n",
        "test_set_torch = dataset(test_set['filename'].values.tolist(), onehot_labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz4BxgfZN0Qu"
      },
      "source": [
        "# Data Loader.\n",
        "training_generator = DataLoader(train_set_torch, batch_size=1, shuffle=False, num_workers=0)\n",
        "validation_generator = DataLoader(test_set_torch, batch_size=1, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lzOGxMOo1UN"
      },
      "source": [
        "### Testing Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr97Ss9nLZxv"
      },
      "source": [
        "# Get a random audio file and label from dataset\n",
        "dataiter = iter(DataLoader(train_set_torch, batch_size=1, shuffle=True, num_workers=0))\n",
        "audio_to_test, label_to_test = dataiter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOFuGx5ePE7Q"
      },
      "source": [
        "# Calculate Spectrogram of the audio file to test\n",
        "specgram = torchaudio.transforms.Spectrogram(n_fft=2048)(audio_to_test[0,0,:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0-oWPJiSI17"
      },
      "source": [
        "# Plot Spectrogram of audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(20*specgram.log10().numpy(), cmap='gray')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWizAlzH0X1v"
      },
      "source": [
        "# Plot Waveform of audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(audio_to_test[0,0,:])\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHmwsO0WSSIL"
      },
      "source": [
        "# Listen to audio\n",
        "ipd.Audio(audio_to_test[0,0,:], rate=44100) # load a local WAV file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM_60weBn7c_"
      },
      "source": [
        "## PyTorch Analysis Filter Bank / Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klbldM3hSUX4"
      },
      "source": [
        "# Model Parameters\n",
        "in_channels = 1\n",
        "n_subbands = 1024\n",
        "filter_length = 2048\n",
        "downsampling = 1024\n",
        "padding = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkzqOpAuPTkx"
      },
      "source": [
        "# Analysis Filter Bank / Encoder\n",
        "class Encoder(torch.nn.Module):\n",
        "  \"\"\" Convolutional Neural Network Analysis Filter Bank for Musical Instruments Classification\n",
        "\n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  def __init__(self, in_channels=1,n_subbands=1024,filter_length=2048,downsampling = 1024, padding=1024, bias=False):\n",
        "    super(Encoder, self).__init__()\n",
        "    # Parameters\n",
        "    self.in_channels = in_channels\n",
        "    self.n_subbands = n_subbands\n",
        "    self.filter_length=filter_length\n",
        "    self.downsampling=downsampling\n",
        "    self.padding = padding\n",
        "    self.bias = bias\n",
        "    # Layers\n",
        "    self.conv1 = torch.nn.Conv1d(in_channels=self.in_channels, out_channels=self.n_subbands, kernel_size=self.filter_length, \n",
        "                                 stride=self.downsampling, padding=self.padding, bias=self.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXUE4b12glzW"
      },
      "source": [
        "### Weights Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1mkhdFigq1h"
      },
      "source": [
        "# Weights Initialization Function\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        #torch.nn.init.zeros_(m.bias.data)\n",
        "    if isinstance(m, nn.ConvTranspose1d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        #torch.nn.init.zeros_(m.bias.data)\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        torch.nn.init.zeros_(m.bias.data)\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "        torch.nn.init.zeros_(m.bias.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od8m27btuptw"
      },
      "source": [
        "### Testing Encoder before Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-90zSgSuxYb"
      },
      "source": [
        "# Create Analysis Filter Bank model\n",
        "analysisFB = Encoder()\n",
        "# Initialize weights\n",
        "analysisFB.apply(weights_init)\n",
        "# Send to Device\n",
        "analysisFB.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfrUhzEvu5lC"
      },
      "source": [
        "test_encoder = analysisFB(audio_to_test.to(device))\n",
        "print('Input Shape', audio_to_test.shape)\n",
        "print('Output Shape', test_encoder.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_08PYeSvjI4"
      },
      "source": [
        "# Display Number of Trainable Parameters\n",
        "pytorch_total_params = sum(p.numel() for p in analysisFB.parameters() if p.requires_grad)\n",
        "print(\"Number of Trainable Parameters:\",pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuUZq3wMvq9j"
      },
      "source": [
        "# Plot of encoded audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(test_encoder[0,:,:].detach().cpu().numpy(), cmap='gray')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA62Vh1oxiJe"
      },
      "source": [
        "## PyTorch Synthesis Filter Bank / Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO54U8-L0Emd"
      },
      "source": [
        "# Model Parameters\n",
        "out_channels = 1\n",
        "n_subbands = 1024\n",
        "filter_length = 2048\n",
        "upsampling = 1024\n",
        "dilatation=1\n",
        "padding = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU5IVFACzHpT"
      },
      "source": [
        " # Decoder\n",
        "class Decoder(torch.nn.Module):\n",
        "  \"\"\" Convolutional Neural Network Analysis Filter Bank for Musical Instruments Classification\n",
        "\n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  def __init__(self, n_subbands=1024,out_channels=1, filter_length=2048, umpsampling=1024, dilatation=1, padding=1, bias=False):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.n_subbands = n_subbands\n",
        "    self.out_channels = out_channels\n",
        "    self.filter_length=filter_length\n",
        "    self.upsampling=upsampling\n",
        "    self.dilatation=dilatation\n",
        "    self.padding=padding\n",
        "    self.bias=bias\n",
        "    self.conv1 = torch.nn.ConvTranspose1d(in_channels=self.n_subbands, out_channels=self.out_channels , kernel_size=self.filter_length, \n",
        "                                          stride=self.upsampling, dilation=self.dilatation, padding=self.padding, bias=self.bias)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBgPcyJg0msa"
      },
      "source": [
        "### Testing Decoder before Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYrCDcbU0NBP"
      },
      "source": [
        "# Create Synthesis Filter Bank Model\n",
        "synthesisFB = Decoder()\n",
        "# Initialize weights\n",
        "synthesisFB.apply(weights_init)\n",
        "# Send to Device\n",
        "synthesisFB.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-eo07t1SVL"
      },
      "source": [
        "# Display Number of Trainable Parameters\n",
        "pytorch_total_params = sum(p.numel() for p in synthesisFB.parameters() if p.requires_grad)\n",
        "print(\"Number of Trainable Parameters:\",pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGfVTW_81kX7"
      },
      "source": [
        "# Test\n",
        "test_decoder = synthesisFB(test_encoder)\n",
        "print('Input Shape: (Encoded)', test_encoder.shape)\n",
        "print('Output Shape: (Decoded)', test_decoder.shape)\n",
        "print(\"Audio_to_test Shape\", audio_to_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BudUOWyw3EVu"
      },
      "source": [
        "# Create Synthesis Filter Bank Model\n",
        "synthesisFB = Decoder()\n",
        "# Initialize weights\n",
        "synthesisFB.apply(weights_init)\n",
        "synthesisFB.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbu5Tf1RBnWE"
      },
      "source": [
        "# Calculate Spectrogram of the reconstructed audio\n",
        "specgram_decoded_audio = torchaudio.transforms.Spectrogram()(test_decoder[0,0,:].to('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eYEeWrfDX_0"
      },
      "source": [
        "# Plot Spectrogram of reconstructed audio\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(20*specgram_decoded_audio.log10().detach().numpy(), cmap='gray')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHlhdK35BUkh"
      },
      "source": [
        "# Plot Waveform of audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(test_decoder[0,0,:].detach().cpu().numpy())\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL2AFhk5626s"
      },
      "source": [
        "\n",
        "display(ipd.Audio(test_decoder[0,0,:].detach().cpu().numpy(), rate=44100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohzQcZ162e8r"
      },
      "source": [
        "## PyTorch CNN Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_XTB4GR68mY"
      },
      "source": [
        "# Model Parameters\n",
        "n_classes=20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TPkwTCr60N_"
      },
      "source": [
        "class classificationModel(torch.nn.Module):\n",
        "  \"\"\" CNN CLassifier for an Analysis Filter Bank for Musical Instruments Classification\n",
        "  \n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  def __init__(self, n_classes=20):\n",
        "    super(classificationModel, self).__init__()\n",
        "    self.n_classes=n_classes\n",
        "    \n",
        "    self.conv1 = torch.nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool1 = torch.nn.MaxPool2d(2)\n",
        "    self.dropout1 = torch.nn.Dropout(p=0.4)\n",
        "    self.conv2 = torch.nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
        "    self.dropout2 = torch.nn.Dropout(p=0.4)\n",
        "    self.adpavpool = torch.nn.AdaptiveAvgPool2d((8,8))\n",
        "    self.fc1 = torch.nn.Linear(8*8, 32)\n",
        "    self.fc2 = torch.nn.Linear(32, self.n_classes)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.unsqueeze(0)\n",
        "    x = self.conv1(x)\n",
        "    x = self.pool1(x)\n",
        "    x = self.dropout1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.adpavpool(x)\n",
        "    x = x.view(x.size()[0], -1)\n",
        "    x = torch.sigmoid(self.fc1(x))\n",
        "    x = F.softmax(self.fc2(x), dim=-1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtwtX3hYGM-I"
      },
      "source": [
        "### Test Classification Model before Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8LhNI8_Gvfj"
      },
      "source": [
        "# Create Classification Model\n",
        "classify = classificationModel()\n",
        "# Initialize weights\n",
        "classify.apply(weights_init)\n",
        "# Send to Device\n",
        "classify.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-8xblPwHFCo"
      },
      "source": [
        "# Display Number of Trainable Parameters\n",
        "pytorch_total_params = sum(p.numel() for p in classify.parameters() if p.requires_grad)\n",
        "print(\"Number of Trainable Parameters:\",pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_ql9mTvHIEb"
      },
      "source": [
        "# Test\n",
        "test_classify = classify(test_encoder)\n",
        "print(\"Predicted Class:\", np.argmax(test_classify.detach().cpu().numpy()))\n",
        "print('Correct Class', np.argmax(label_to_test.detach().cpu().numpy()))\n",
        "print(\"Output of Classifier Shape:\", test_classify.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEw-c8ZJHgJQ"
      },
      "source": [
        "## PyTorch CNN Autoencoder Model with Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeUEX0ItJEYB"
      },
      "source": [
        "# Audoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "  \"\"\" CNN Autoencoder with an Embedded CLassifier for Musical Instruments Classification\n",
        "  \n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, encoder, classifier, decoder):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.classifier = classifier\n",
        "    self.decoder = decoder\n",
        "    \n",
        "  def forward(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    classified = self.classifier(encoded)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return encoded, decoded, classified"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjiylGkpJzzi"
      },
      "source": [
        "### Testing Autoencoder before Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9s2uPF3KN3R"
      },
      "source": [
        "# Create Autoencoder Model\n",
        "autoencoder = Autoencoder(analysisFB,classify,synthesisFB)\n",
        "# Send to Device\n",
        "autoencoder.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4gFCsvgLv0W"
      },
      "source": [
        "# Test\n",
        "test_encoded, test_output, test_type = autoencoder(audio_to_test.to(device))\n",
        "print('Encoded Shape', test_encoded.shape)\n",
        "print('Decoded Shape', test_output.shape)\n",
        "print('Predicted Class', np.argmax(test_type.detach().cpu().numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY8dVZ-EMBlF"
      },
      "source": [
        "## Define a Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH-yBK_cMDes"
      },
      "source": [
        "class categorical_cross_entropy(nn.Module):\n",
        "    ''' Categorical Cross Entropy similar to Keras/TensorFlow\n",
        "        \"Categorical crossentropy between an output tensor and a target tensor\" - https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
        "        https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/backend.py\n",
        "        target: A tensor of the same shape as `inputX`.\n",
        "        inputX: A tensor resulting from a softmax\n",
        "\n",
        "        Ported to PyTorch by Renato Profeta, October 2020\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(categorical_cross_entropy, self).__init__()\n",
        "\n",
        "    def forward(self, inputX, target):\n",
        "        eps=1e-10\n",
        "        tmp = inputX.clone()\n",
        "        tmp /= torch.sum(tmp)\n",
        "        torch.clamp_(tmp, min=eps, max = 1-eps)\n",
        "        return torch.mean(-torch.sum(target * torch.log(tmp.double()), dim=-1), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyHvO6D8M2bp"
      },
      "source": [
        "## Set a Loss Function and an Optimizer for the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj8DkmSYOHCd"
      },
      "source": [
        "# Loss Functions\n",
        "loss_classification = categorical_cross_entropy()\n",
        "loss_decoder = torch.nn.MSELoss()\n",
        "\n",
        "# Optimizer\n",
        "lr=0.01\n",
        "optimizer = optim.SGD(autoencoder.parameters(), lr=lr)\n",
        "#optimizer = optim.Adagrad(autoencoder.parameters())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2gaFcKMObKH"
      },
      "source": [
        "## Auxiliary Functions for Progress Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teZeO-d2OxPj"
      },
      "source": [
        "# https://colab.research.google.com/drive/11v_mM2ImWdKDs_4qkoB9TdsQiPgVeeo2#scrollTo=NQgIwI5WC-07        \n",
        "class ProgressMonitor(object):\n",
        "    \"\"\"\n",
        "    Custom IPython progress bar\n",
        "    \"\"\"\n",
        "    \n",
        "    tmpl_train =\"\"\"\n",
        "        <p> Train Epoch: {epoch} / {num_epochs} <br>\n",
        "        Step: {value} / {length} - Train <br>\n",
        "        Loss Classification: {loss_classify:0.4f} / Accuracy Classification: {accuracy_classify:0.4f} <br> \n",
        "        Loss Decoder: {loss_decoder:0.4f} <br>\n",
        "        Total Loss: {loss_total:0.4f}</p>\n",
        "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "        <br>\"\"\"\n",
        "    \n",
        "    tmpl_test= \"\"\"\n",
        "        <p>Test Epoch: {epoch} / {num_epochs} <br>\n",
        "        Step: {value} / {length} - Test <br>\n",
        "        Loss Classification: {loss_classify:0.4f} / Accuracy Classification: {accuracy_classify:0.4f} <br> \n",
        "        Loss Decoder: {loss_decoder:0.4f} <br>\n",
        "        Total Loss: {loss_total:0.4f}</p> </p>\n",
        "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
        "        <br>\"\"\"\n",
        "\n",
        "    def __init__(self, length, mode):\n",
        "        self.length = length\n",
        "        self.count = 0\n",
        "        self.mode = mode\n",
        "        self.display = display(self.html(0, 0, 0, 0, 0, 0, 0, mode), display_id=True)   \n",
        "        \n",
        "    def html(self, count, epoch, num_epochs, loss_classify, accuracy_classify, loss_decoder, loss_total,mode=\"train\"):\n",
        "        if mode==\"train\":\n",
        "            return HTML(self.tmpl_train.format(length=self.length, value=count, epoch=epoch, num_epochs=num_epochs, \n",
        "                                               loss_classify=loss_classify, accuracy_classify=accuracy_classify,\n",
        "                                               loss_decoder=loss_decoder,loss_total=loss_total))\n",
        "        else:\n",
        "            return HTML(self.tmpl_test.format(length=self.length, value=count, epoch=epoch, num_epochs=num_epochs, \n",
        "                                               loss_classify=loss_classify, accuracy_classify=accuracy_classify,\n",
        "                                               loss_decoder=loss_decoder, loss_total=loss_total))\n",
        "            \n",
        "    def update(self, count, epoch, num_epochs, loss_classify, accuracy_classify,loss_decoder,loss_total,mode=\"train\"):\n",
        "        self.count += count\n",
        "        self.display.update(self.html(self.count, epoch, num_epochs, loss_classify, accuracy_classify, loss_decoder, loss_total, mode))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPdwVAEQO0RC"
      },
      "source": [
        "# https://colab.research.google.com/drive/1gJAAN3UI9005ecVmxPun5ZLCGu4YBtLo#scrollTo=ZvoPaJvs7Eem\n",
        "class AverageBase(object):\n",
        "    \n",
        "    def __init__(self, value=0):\n",
        "        self.value = float(value) if value is not None else None\n",
        "       \n",
        "    def __str__(self):\n",
        "        return str(round(self.value, 4))\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.value\n",
        "    \n",
        "    def __format__(self, fmt):\n",
        "        return self.value.__format__(fmt)\n",
        "    \n",
        "    def __float__(self):\n",
        "        return self.value\n",
        "    \n",
        "\n",
        "class RunningAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    Keeps track of a cumulative moving average (CMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, value=0, count=0):\n",
        "        super(RunningAverage, self).__init__(value)\n",
        "        self.count = count\n",
        "        \n",
        "    def update(self, value):\n",
        "        self.value = (self.value * self.count + float(value))\n",
        "        self.count += 1\n",
        "        self.value /= self.count\n",
        "        return self.value\n",
        "\n",
        "class MovingAverage(AverageBase):\n",
        "    \"\"\"\n",
        "    An exponentially decaying moving average (EMA).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, alpha=0.99):\n",
        "        super(MovingAverage, self).__init__(None)\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def update(self, value):\n",
        "        if self.value is None:\n",
        "            self.value = float(value)\n",
        "        else:\n",
        "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
        "        return self.value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXvnO2LDO3rC"
      },
      "source": [
        "## Auxiliary Functions to save Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IHMZxZlPIdC"
      },
      "source": [
        "# Save a Model\n",
        "def save_checkpoint(optimizer, loss_classification,loss_decoder, model, epoch, filename):\n",
        "    global bestm\n",
        "    checkpoint_dict = {\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'model': model.state_dict(),\n",
        "        'epoch': epoch,\n",
        "        'loss_classification': loss_classification.state_dict(),\n",
        "        'loss_decoder': loss_decoder.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint_dict, filename)\n",
        "\n",
        "# Load a Model\n",
        "def load_checkpoint(optimizer, loss_classification, loss_decoder, model, filename):\n",
        "    checkpoint_dict = torch.load(filename)\n",
        "    epoch = checkpoint_dict['epoch']\n",
        "    model.load_state_dict(checkpoint_dict['model'])\n",
        "    loss_classification.load_state_dict(checkpoint_dict['loss_classification'])\n",
        "    loss_decoder.load_state_dict(checkpoint_dict['loss_decoder'])\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint_dict['optimizer'])\n",
        "    return epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbsgtpDjPOjw"
      },
      "source": [
        "## Function to Train a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2I-khpDPVAC"
      },
      "source": [
        "# Training Function\n",
        "def trainModel(model, epoch, num_epochs, monitoring=True):\n",
        "  \"\"\" Function to Train a Model\n",
        "\n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  if monitoring:\n",
        "    progress = ProgressMonitor(length=len(train_set), mode=\"train\")\n",
        "  \n",
        "  # Initialize Metrics\n",
        "  train_loss_classify = MovingAverage()\n",
        "  train_loss_decoder = MovingAverage()\n",
        "  train_loss_total = MovingAverage()\n",
        "  train_acc = MovingAverage()\n",
        "    \n",
        "  # Train Stage\n",
        "  model.train()\n",
        "    \n",
        "  # keep track of X predictions amd metrics\n",
        "  x_pred = []\n",
        "\n",
        "  for i, (batch, targets) in enumerate(training_generator):\n",
        "    # Move the training data to the GPU\n",
        "    batch = batch.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # clear previous gradient computation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward propagation\n",
        "    encoded, decoded, classified = model(batch)\n",
        "\n",
        "    # Check the array with higher length\n",
        "    if decoded.size() > batch.size():\n",
        "      target = torch.zeros(decoded.shape).to(device)\n",
        "      target[0,0,:batch.shape[-1]]=batch[0,0,:]\n",
        "    else:\n",
        "      target = batch[:,:,:decoded.shape[-1]]\n",
        "\n",
        "    #target=target.to(device)\n",
        "    # calculate the loss\n",
        "    loss1 = loss_classification(classified, targets)\n",
        "    loss2 = loss_decoder(decoded, target)\n",
        "\n",
        "    loss = w_class*loss1 + w_decoder*loss2\n",
        "    # backpropagate to compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # update model weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # update average loss\n",
        "    train_loss_classify.update(loss1)\n",
        "    train_loss_decoder.update(loss2)\n",
        "    train_loss_total.update(loss)\n",
        "            \n",
        "    # save X predictions\n",
        "    x_pred.extend(classified.argmax(dim=-1).cpu().numpy())\n",
        "        \n",
        "    # calculate accuracy\n",
        "    x_pred_torch = torch.tensor(x_pred, dtype=torch.int64)\n",
        "    accuracy = torch.mean((x_pred_torch == torch.tensor(np.argmax(onehot_labels_train[:len(x_pred)],axis=1), dtype=torch.int64)).float())\n",
        "        \n",
        "    # update average accuracy\n",
        "    train_acc.update(accuracy)\n",
        "            \n",
        "    # Update Progress Bar\n",
        "    if monitoring:\n",
        "      progress.update(batch.shape[0], epoch, num_epochs, train_loss_classify, train_acc, train_loss_decoder, train_loss_total, mode=\"train\")\n",
        "  # Save a checkpoint\n",
        "  checkpoint_filename = 'checkpoints/AutoencoderInstrumetClassif-{:03d}.pkl'.format(epoch)\n",
        "  save_checkpoint(optimizer, loss_classification, loss_decoder, model, epoch, checkpoint_filename)\n",
        "  return train_loss_classify.value, train_acc.value , train_loss_decoder.value, train_loss_total.value, x_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoevRJrpciFx"
      },
      "source": [
        "## Funtion to Test a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNtBYz7KcSDe"
      },
      "source": [
        "def testModel(model, epoch, num_epochs, monitoring=True):\n",
        "  \"\"\" Function to Test a Model\n",
        "\n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  if monitoring:\n",
        "    #Create a Progress Bar\n",
        "    progress = ProgressMonitor(length=len(test_set), mode=\"test\")\n",
        "    \n",
        "    \n",
        "  # validation phase\n",
        "  model.eval()\n",
        "    \n",
        "  # Initialize Metrics\n",
        "  test_loss_classify = MovingAverage()\n",
        "  test_loss_decoder = MovingAverage()\n",
        "  test_loss_total = MovingAverage()\n",
        "  test_acc = MovingAverage()\n",
        "\n",
        "  # keep track of predictions\n",
        "  y_pred = []\n",
        "    \n",
        "  with torch.no_grad():\n",
        "    for batch, targets in validation_generator:\n",
        "      \n",
        "      # Move the training batch to the GPU\n",
        "      batch = batch.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      # forward propagation\n",
        "      encoded, decoded, classified = model(batch)\n",
        "\n",
        "      # Check the array with higher length\n",
        "      if decoded.size() > batch.size():\n",
        "        target = torch.zeros(decoded.shape).to(device)\n",
        "        target[0,0,:batch.shape[-1]]=batch[0,0,:]\n",
        "      else:\n",
        "        target = batch[:,:,:decoded.shape[-1]]\n",
        "\n",
        "      # calculate the loss\n",
        "      loss1 = loss_classification(classified, targets)\n",
        "      loss2 = loss_decoder(decoded, target)\n",
        "\n",
        "      loss = w_class*loss1 + w_decoder*loss2\n",
        "\n",
        "      # update average loss\n",
        "      test_loss_classify.update(loss1)\n",
        "      test_loss_decoder.update(loss2)\n",
        "      test_loss_total.update(loss)\n",
        "\n",
        "      # save predictions\n",
        "      y_pred.extend(classified.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "      # Validation Accuracy\n",
        "      y_pred_torch = torch.tensor(y_pred, dtype=torch.int64)\n",
        "      accuracy = torch.mean((y_pred_torch == torch.tensor(np.argmax(onehot_labels_test[:len(y_pred)],axis=1), dtype=torch.int64)).float())\n",
        "      test_acc.update(accuracy)\n",
        "\n",
        "      # Update Progress Bar\n",
        "      if monitoring:\n",
        "        progress.update(batch.shape[0], epoch, num_epochs, test_loss_classify, test_acc, test_loss_decoder, test_loss_total, mode=\"test\")\n",
        "\n",
        "        \n",
        "    return test_loss_classify.value, test_loss_decoder.value, test_loss_total.value, test_acc.value, y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd5VLD6rQNr9"
      },
      "source": [
        "## Experiment Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0JswfOdQ8eP"
      },
      "source": [
        "# Training Parameters\n",
        "\n",
        "n_epochs = 2\n",
        "\n",
        "# Weights for Loss Functions\n",
        "w_class = 1\n",
        "w_decoder=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4bse_xySoFK"
      },
      "source": [
        "writer = SummaryWriter()\n",
        "writer.add_graph(autoencoder,audio_to_test.to(device) )\n",
        "writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZP32pdFSw-n"
      },
      "source": [
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-pjx9fvmPiD"
      },
      "source": [
        "## Function to Run an Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSfm3HkLuQC6"
      },
      "source": [
        "def experiment(model, num_epochs = n_epochs, first_epoch = 1, monitoring=True, test_monitor=True):\n",
        "  \"\"\" Function to Test a Model\n",
        "\n",
        "  Author: Renato de Castro Rabelo Profeta, October 2020, TU Ilmenau, Germany\n",
        "  \"\"\"\n",
        "  \n",
        "  #Initialze Metrics\n",
        "  train_losses = []\n",
        "  train_accuracies = []\n",
        "  train_losses_decoder = []\n",
        "  train_losses_total = []\n",
        "  valid_losses = []\n",
        "  valid_accuracies = []\n",
        "  valid_losses_decoder = []\n",
        "  valid_losses_total=[]\n",
        "  valid_predictions = []\n",
        "  \n",
        "  for epoch in range(first_epoch, num_epochs+1):\n",
        "    #Train Model\n",
        "    train_loss, train_acc, train_loss_decoder, train_loss_total, x_pred =trainModel(model, epoch, num_epochs, monitoring)\n",
        "    #Save Test Losses and Accuracies\n",
        "    train_losses.append(train_loss)\n",
        "    train_losses_decoder.append(train_loss_decoder)\n",
        "    train_losses_total.append(train_loss_total)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    if test_monitor:\n",
        "      #Test Model\n",
        "      valid_loss, test_loss_decoder, test_loss_total, valid_acc, y_pred = testModel(model, epoch, num_epochs, monitoring)\n",
        "    else:\n",
        "      valid_loss=0\n",
        "      test_loss_decoder=0\n",
        "      test_loss_total=0\n",
        "      valid_acc = 0\n",
        "      y_pred = 0\n",
        "      \n",
        "    #Save Test Losses and Accuracies\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_losses_decoder.append(test_loss_decoder)\n",
        "    valid_losses_total.append(test_loss_total)\n",
        "    valid_accuracies.append(valid_acc)\n",
        "    valid_predictions.append(y_pred)\n",
        "\n",
        "\n",
        "    writer.add_scalars('Losses', {'Train Classification Loss':train_loss,\n",
        "                                    'Test Classification Loss':valid_loss,\n",
        "                                    'Train Decoder Loss*w':train_loss_decoder*w_decoder,\n",
        "                                    'Test Decoder Loss*w':test_loss_decoder*w_decoder,\n",
        "                                    'Train Total Loss':train_loss_total,\n",
        "                                    'Test Total Loss': test_loss_total}, epoch)\n",
        "    \n",
        "    writer.add_scalars('Classification Accuracy', {'Train Classification ':train_acc,\n",
        "                                    'Test Classification':valid_acc}, epoch)\n",
        "\n",
        "    writer.flush()\n",
        "\n",
        "  writer.close()              \n",
        "  return {\"train_loss\": train_losses, \"train_loss_decoder\": train_losses_decoder, \"train_loss_total\": train_losses_total, \"train_accuracies\": train_accuracies,\n",
        "            \"valid_loss\": valid_losses, \"valid_loss_decoder\": valid_losses_decoder, \"valid_loss_total\": valid_losses_total, \"valid_accuracies\": valid_accuracies,\n",
        "            \"valid_predictions\":  valid_predictions}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp9RgAtVvv0p"
      },
      "source": [
        "## Run an Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biYSrtdrmVUy"
      },
      "source": [
        "# Run Experiment\n",
        "hist = experiment(autoencoder, num_epochs=n_epochs, monitoring=True, test_monitor=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jdhykxi6nAL"
      },
      "source": [
        "## Resume an Experiment from a saved Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tU1KOd26spN"
      },
      "source": [
        "n_epochs=4\n",
        "epoch = load_checkpoint(optimizer, loss_classification, loss_decoder, autoencoder, './checkpoints/AutoencoderInstrumetClassif-002.pkl')\n",
        "print('Resuming training from epoch', epoch)\n",
        "hist = experiment(autoencoder, num_epochs=n_epochs, first_epoch=epoch+1, test_monitor=True, monitoring=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CZ3pPNVwuYx"
      },
      "source": [
        "## Experiment Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2FBDNdcdeXb"
      },
      "source": [
        "epochs = range(1, len(hist[\"train_loss\"]) + 1)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, hist[\"train_loss\"], '-o', label='Training loss Classification')\n",
        "plt.plot(epochs, hist[\"valid_loss\"], '-o', label='Validation loss CLassification')\n",
        "plt.legend()\n",
        "plt.title('Learning curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(epochs)\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, hist[\"train_loss_decoder\"], '-o', label='Training loss Decoder')\n",
        "plt.plot(epochs, hist[\"valid_loss_decoder\"], '-o', label='Validation loss Decoder')\n",
        "plt.legend()\n",
        "plt.title('Learning curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(epochs)\n",
        "plt.grid()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, hist[\"train_loss_total\"], '-o', label='Training loss Total')\n",
        "plt.plot(epochs, hist[\"valid_loss_total\"], '-o', label='Validation loss Total')\n",
        "plt.legend()\n",
        "plt.title('Learning curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(epochs)\n",
        "plt.grid()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs, hist[\"train_accuracies\"], '-o', label='Training accuracy Classification')\n",
        "plt.plot(epochs, hist[\"valid_accuracies\"], '-o', label='Validation accuracy Classification')\n",
        "plt.legend()\n",
        "plt.title('Learning curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xticks(epochs)\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjKipUlxdkFw"
      },
      "source": [
        "# Number of Validation Classification Errors\n",
        "num_errors = torch.sum((torch.tensor(hist[\"valid_predictions\"]) != torch.tensor(np.argmax(onehot_labels_test,axis=1))).float())\n",
        "print('Validation errors {} (out of {})'.format(int(num_errors), len(test_set)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22NLui5RRbdV"
      },
      "source": [
        "# Validation Classification Mistakes\n",
        "error_indicator = torch.tensor(hist[\"valid_predictions\"]) != torch.tensor(np.argmax(onehot_labels_test,axis=1))\n",
        "print(\"Wrongly predicted Audio Files\", test_set['filename'].values[np.where(error_indicator[0,:])])\n",
        "print(\"Correct Classes:\", test_set['class'].values[np.where(error_indicator[0,:])])\n",
        "print(\"Predicted as:\",labelencoder.inverse_transform(np.ravel(np.array(hist[\"valid_predictions\"])[np.where(error_indicator)])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rbr-z2luR568"
      },
      "source": [
        "# Back to Labels\n",
        "predictions_labels=labelencoder.inverse_transform(np.ravel(hist[\"valid_predictions\"]));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGHbpcGOThqx"
      },
      "source": [
        "# Recall - the ability of the classifier to find all the positive samples\n",
        "print(\"Recall: \", recall_score(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:],average=None))\n",
        "\n",
        "# Precision - The precision is intuitively the ability of the classifier not to \n",
        "#label as positive a sample that is negative\n",
        "print(\"Precision: \", precision_score(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:],average=None, zero_division=0))\n",
        "\n",
        "# F1-Score - The F1 score can be interpreted as a weighted average of the precision \n",
        "#and recall\n",
        "print(\"F1-Score: \", f1_score(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:], average=None))\n",
        "\n",
        "# Accuracy - the number of correctly classified samples\n",
        "print(\"Accuracy: %.2f  ,\" % accuracy_score(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:] ,normalize=True), accuracy_score(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:],normalize=False) )\n",
        "print(\"Number of samples:\",classes_int_test.shape[0])\n",
        "\n",
        "print(classification_report(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:], zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl3JJFHDT59f"
      },
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(classes_int_test, np.array(hist[\"valid_predictions\"])[0,:])\n",
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsBIVnb-U5ZU"
      },
      "source": [
        "# Function to Plot Confusion Matrix\n",
        "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    \"\"\"\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qsBXgtc0Ihu"
      },
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "plt.figure(figsize=(16,12))\n",
        "plot_confusion_matrix(cnf_matrix, classes=labelencoder.classes_,\n",
        "                      title='Confusion matrix, without normalization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofjFvYsz0JGX"
      },
      "source": [
        "### Playback of Audio Files after Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INXW4jehn8gw"
      },
      "source": [
        "# Test\n",
        "test_encoded, test_output, test_type = autoencoder(audio_to_test.to(device))\n",
        "print('Original Shape', audio_to_test.shape)\n",
        "print('Encoded Shape', test_encoded.shape)\n",
        "print('Decoded Shape', test_output.shape)\n",
        "print('Predicted Class', np.argmax(test_type.detach().cpu().numpy()))\n",
        "print('Correct Class', np.argmax(label_to_test.detach().cpu().numpy()))\n",
        "print('MSE', mean_squared_error(audio_to_test[0,0,:], test_output[0,0,:audio_to_test.shape[-1]].detach().cpu()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2BzOWC7DtGG"
      },
      "source": [
        "# Plot Waveform of audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(audio_to_test[0,0,:])\n",
        "plt.plot(test_output[0,0,:].detach().cpu().numpy())\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZEmRUt1vH4n"
      },
      "source": [
        "display(ipd.Audio(test_output[0,0,:].detach().cpu().numpy(), rate=44100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOjT5nwD123Z"
      },
      "source": [
        "# Plot of encoded audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(test_encoded[0,:,:].detach().cpu().numpy(), cmap='gray')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TUkOCRzZTdL"
      },
      "source": [
        "# Get a random audio file and label from dataset\n",
        "dataiter = iter(DataLoader(test_set_torch, batch_size=1, shuffle=True, num_workers=0))\n",
        "audio_to_test, label_to_test = dataiter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzbbiteUZZ1v"
      },
      "source": [
        "# Test\n",
        "test_encoded, test_output, test_type = autoencoder(audio_to_test.to(device))\n",
        "print('Original Shape', audio_to_test.shape)\n",
        "print('Encoded Shape', test_encoded.shape)\n",
        "print('Decoded Shape', test_output.shape)\n",
        "print('Predicted Class', np.argmax(test_type.detach().cpu().numpy()))\n",
        "print('Correct Class', np.argmax(label_to_test.detach().cpu().numpy()))\n",
        "print('MSE', mean_squared_error(audio_to_test[0,0,:], test_output[0,0,:audio_to_test.shape[-1]].detach().cpu()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o306DSUZgdY"
      },
      "source": [
        "# Plot Waveform of audio to test\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(audio_to_test[0,0,:])\n",
        "plt.plot(test_output[0,0,:].detach().cpu().numpy())\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx7aLCmRZ0LJ"
      },
      "source": [
        "# Calculate Spectrogram of the audio file to test\n",
        "specgram = torchaudio.transforms.Spectrogram(n_fft=2048)(audio_to_test[0,0,:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogVm0cj_Z2nv"
      },
      "source": [
        "# Plot Spectrogram of audio to test\n",
        "plt.figure(figsize=(6,12))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(specgram.numpy(), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid()\n",
        "# Plot of encoded audio to test\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(test_encoded[0,:,:].detach().cpu().numpy(), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lKlaJZOaDrC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkRrEPSYKb9u"
      },
      "source": [
        "!ls checkpoints -l\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph9ShWONKfH6"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download('./checkpoints/basicInstrumetClassif-382.pkl') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghg3F0wtKlTc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}